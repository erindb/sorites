---
title: "Sorites"
author: ""
header-includes:
   - \usepackage{float}
output:
  pdf_document:
    number_sections: true
    fig_caption: true
bibliography: sorites.bib
---

# Introduction

```{r global_options, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = F, warning = F, cache = T, message = F,
                      sanitiz = F, fig.width = 5, fig.height = 3)
```

```{r libraries}
library(knitr)
source("../analysis/startup.R")
library(ggrepel)
set.seed(123)
library(corrplot)
```

{{SKETCH INTRO}}

# Experiment 1: Sorites Statements

```{r sorites data}
df11 = read.csv("../data/sorites/data_exp11_2015_06_05_14.csv", stringsAsFactors = F)
reward = df11$reward[[1]]
mean_time = df11$Answer.time_in_minutes %>% mean() %>% round()
df11 = df11 %>%
  select(workerid, Answer.phrasing, Answer.responses,
         Answer.time_in_minutes, Answer.subj_data) %>%
  rename(phrasing = Answer.phrasing,
         time = Answer.time_in_minutes)
df11 = do.call(rbind, mapply(
  function(w, subj_data, responses) {
    df = responses %>% fromJSON() %>% as.data.frame()
    df$workerid = w
    df$trial_number = 1:nrow(df)
    s = fromJSON(subj_data)
    df$language = s$language
    return(df)
  },
  df11$workerid,
  df11$Answer.subj_data,
  df11$Answer.responses,
  SIMPLIFY = F
))
df11$response = num(df11$response)
n_participants = df11 %>% group_by(qtype, object, dollar_amount) %>%
  summarise(n = length(response)) %>% .$n
stopifnot(min(n_participants) == max(n_participants))
n_participants_total = n_participants[[1]]
n_questions = df11 %>% group_by(workerid) %>%
  summarise(n = length(response)) %>% .$n
stopifnot(min(n_questions) == max(n_questions))
n_questions = n_questions[[1]]
likert_lower = min(df11$response)
likert_upper = max(df11$response)
stopifnot(length(likert_lower:likert_upper)==9)
df11 = df11 %>%
  filter(language %in% c("english", "English", "Engllish")) %>%
  mutate(response = response + 1)
n_participants = df11$workerid %>% unique() %>% length()
n_excluded = n_participants_total - n_participants
df11 %>% select(workerid, qtype, dollar_amount, object, response) %>%
  mutate(id = "11") %>%
  write.csv(file = "../data/sorites/final_sorites.csv")
```

## Participants

We recruited `r n_participants_total` participants with US IP addresses over Amazon's Mechanical Turk.
`r n_excluded` participants were exluded from analysis for not being native English speakers, leaving `r n_participants` participants for analysis.
The experiment took about `r mean_time` minutes and participants were paid `r reward`.

## Materials

The experiment consisted of `r n_questions` questions. There were 2 basic question types, *concrete* and *inductive* of the form:

* *Concrete*: An [OBJECT] that costs $[PRICE VALUE] is expensive.
* *Inductive*: An [OBJECT] that costs $[PRICE VALUE] is expensive.

There were 5 object categories (coffee maker, laptop, headphones, watch, and sweater) and 5 price values for each object category and premise type. The price values based on pilot experiments to constitute similar standard deviations of the price distribution for each object category and to capture a range of plausible values.

```{r sorites price tables}
dollar_amounts = df11 %>%
  group_by(qtype, object, dollar_amount, level) %>%
  summarise() %>%
  ungroup() %>%
  mutate(dollar_amount = sprintf("%.02f", dollar_amount)) %>%
  spread(object, dollar_amount) %>%
  select(-level)
dollar_amounts %>% filter(qtype=="concrete") %>% kable(caption="Price values for concrete premise.", align="rrrrrr")
dollar_amounts %>% filter(qtype=="inductive") %>% kable(caption="Price values for inductive premise.", align="rrrrrr")
```


## Methods

At the start of the experiment, participants were told they would be asked questions about the prices of different household items. Each question started with a statment in bold, either the *concrete* statement or the *inductive* statement.
For both types of questions, participants gave Likert responses for how much they agreed with the statement, on a scale from "Completely disagree" (1) to "Completely agree" (9).

Each participant then saw all 5 object categories with all 5 price values for each kind of sentence. Trials were presented in random order.

## Results

```{r sorites figure, fig.width=10, fig.height=5, fig.cap="Results of Experiment 1. Error bars are 95% confidence intervals."}
 breaks_fun <- function(x) {
  if (max(x) < 400) {
    c(0, 50, 100, 150, 200)
  # } else if (max(x) < 400) {
  #   c(0, 100, 200, 300)
  } else {
    c(0, 500, 1000, 1500, 2000)
  }
}
df11 %>%
  ggplot(aes(x=dollar_amount, y=response, colour=qtype, shape=qtype, linetype=qtype)) +
  # geom_point(alpha=0.1) +
  # geom_line(alpha=0.05, aes(group=workerid)) +
  stat_summary(geom="pointrange", fun.data="mean_cl_boot", alpha=0.7) +
  facet_wrap(qtype~object, ncol=5, scales="free_x") +
  scale_y_continuous(breaks=1:9, limits=c(0.9, 9.1)) +
  scale_x_continuous(breaks=breaks_fun) +
  xlab("Dollar Amount") +
  ylab("Endorsement Rating") +
  scale_colour_manual(values = c("darkgray", "black"))
```

```{r per item plots}
# df11 %>%
#   ggplot(aes(x=response)) +
#   facet_wrap(dollar_amount ~ qtype) +
#   geom_histogram(binwidth=1)
```

```{r per P plots}
# df11 %>%
#   ggplot(aes(x=response)) +
#   facet_wrap(~workerid) +
#   geom_histogram(binwidth=1)
```

Results of Experiment 1 are shown in Figure 1. We see a range of endorsements from very low (e.g. "A coffee maker that costs \$24.00 is expensive" or "A laptop that costs \$1850.00 less than an expensive laptop is expensive.") to very high (e.g. "A watch that costs \$2000.00 is expensive" or "A sweater that costs \$171.00 less than an expensive sweater is expensive."). We also see a gradual increase in endorsements for the concrete premises (the item is expensive) as the price of the item increases, and a gradual decrease in endorsements for the inductive premise (the less expensive item is expensive) as the _change_ in price between the expensive and less expensive items increases.

```{r cors between Ps}
get_cors = function(df) {
  sorites_cors = df %>% select(workerid, response, qtype, object, dollar_amount) %>%
    spread(workerid, response) %>%
    select(-c(qtype, object, dollar_amount)) %>%
    cor()
  # sorites_cors %>%
  #   corrplot()
  sorites_cors_ci = sorites_cors %>% .[upper.tri(.,diag = F)] %>% mean_cl_boot()
  return(sorites_cors_ci)
}
sorites_cors_ci = get_cors(df11) %>% round(3)
sorites_cors_inductive = get_cors(df11 %>% filter(qtype=="inductive")) %>% round(3)
sorites_cors_concrete = get_cors(df11 %>% filter(qtype=="concrete")) %>% round(3)

report_mean_ci = function(x) {
  paste("mean: ", x$y %>% round(3), ", CI: [", x$ymin %>% round(3), ", ", x$ymax %>% round(3), "]", sep="")
}
```

```{r cors by obj}
# df11 %>% group_by(object) %>%
#   do(get_cors(.)) %>%
#   ungroup()
# df11 %>% group_by(object) %>%
#   do(get_cors(.)) %>%
#   ungroup() %>%
#   ggplot(aes(x=object, y=y, ymin=ymin, ymax=ymax)) +
#   geom_pointrange()
# df11 %>% group_by(object, qtype) %>%
#   do(get_cors(.)) %>%
#   ungroup() %>%
#   ggplot(aes(x=object, y=y, ymin=ymin, ymax=ymax)) +
#   facet_grid(~qtype) +
#   geom_pointrange()
```

Participants tended to be in agreement about these endorsements. The average correlation between participants's responses was `r sorites_cors_ci$y %>% round(3)` (CI: [`r sorites_cors_ci$ymin %>% round(3)`, `r sorites_cors_ci$ymax %>% round(3)`]). 
Aggreement tended to be higher for the concrete premise (`r report_mean_ci(sorites_cors_concrete)`) than for the inductive premise (`r report_mean_ci(sorites_cors_inductive)`).

## Discussion

In this first experiment, we qualitatively capture the three characteristic effects of vagueness:

* Judgements depend on context: Different object categories and price values yield different responses.
* Judgements are systematic: Within a particular context, different people give similar judgements.
* Judgements are graded: They range from very low to very high endorsement and include borderline cases.

In particular, we see strong endorsement of some inductive premises. Importantly this is also graded, with some inductive sentences judged as not good at all.

This suggests rich quantitative patterns to explain.

# Experiment 2: Prior Distributions

Judgements to our sorites premises depended on the object categories. So, in order to model participants' endorsements, it was useful to have as input a measure of people's prior expectations about the prices of these object categories. In experiment 2, we elicit price distributions using a binned histogram approach (@franke_what_2016).

```{r priors data}
df12 = read.csv("../data/priors/data_exp12_2015_04_08.csv", stringsAsFactors = F)
reward = df12$reward[[1]]
df12 = df12 %>%
  select(workerid, starts_with("Answer"))
n_participants_total = nrow(df12)
mean_time = (num(df12$Answer.duration) %>% mean() / 60000) %>% round()
df12 = df12 %>%
  select(-c(Answer.duration, Answer.age, Answer.comments, Answer.cond)) %>%
  gather("trial", "data", -c(Answer.language, workerid))
df12 = df12 %>%
  ##actually, there's no need to leave out non-native speakers for this task
  # filter(Answer.language %in% c('"English"', '"ENGLISH"', '"english"')) %>%
  select(-Answer.language) %>%
  with(., do.call(rbind, mapply(function(w, t, d) {
    d = fromJSON(d)
    d = data.frame(lower = num(d$lowers),
               upper = d$uppers,
               response = num(d$responses),
               item = char(d$item),
               max = d$max,
               workerid = w,
               trial = t)
    return(d)
  }, workerid, trial, data, SIMPLIFY = F)))
df12 = df12 %>%
  mutate(upper = num(ifelse(upper=="infty", max, char(upper)))) %>%
  mutate(mid = (lower + upper)/2)
n_participants = df12$workerid %>% unique() %>% length()
n_excluded = n_participants_total - n_participants
df12 = df12 %>%
  group_by(workerid, item) %>%
  mutate(normed_response = response / sum(response)) %>%
  ungroup()
reformatted_df12 = df12 %>%
  rename(object = item, UB = upper, LB = lower, rating = response, normed_rating = normed_response) %>%
  group_by(workerid, object) %>%
  mutate(bin = 1:length(workerid)) %>%
  select(workerid, object, bin, UB, LB, rating, normed_rating)
reformatted_df12 %>%
  write.csv("../data/priors/final_priors.csv", row.names = F)
```

## Participants

We recruited `r n_participants_total` participants with US IP addresses over Amazon's Mechanical Turk.
The experiment took about `r mean_time` minutes and participants were paid `r reward`.

## Materials

![Screenshot from Experiment 2](img/priors_screenshot.png)

The experiment consisted of 5 question pages, on for each object category. Each page contained vertical slider bars corresponding to a range of prices (e.g. \$0 - \$50 or \$450-\$500). There were 50-80 sliders per page, depending on the object category (see Figure 2). The sliders were shown in rows of 10 sliders each.

There were 5 object categories (coffee maker, laptop, headphones, watch, and sweater). The price ranges for each object category were chosen based on pilot experiments. We wanted sufficient detail about the tails of the distributions, so we chose maximum values for each object category such that the average endorsement of the highest bin was very low. We also wanted sufficient granularity to address the sorites inductive premise, even for very small price values. We therefore chose the width of the bins so that, for every concrete price value \$$x$ and for every inductive price value \$$\varepsilon$ in our sorites premises experiment, we could confidently estimate the probability of an item \$$\epsilon$ less expensive than \$$x$. Our choise of maximum price and bin widths are shown in Table 3. The resulting distributions are fairly smooth, allowing us to interpolate within the bins as needed. Our level of resolution also allowed us to capture detail in especially dense parts of the distributions (usually the smaller ranges).

```{r priors price tables}
priors_table = data.frame(
  c("watch", "laptop", "coffee maker", "sweater", "headphones"),
  c(3000, 2500, 270, 240, 330),
  c(50, 50, 4, 6, 3))
names(priors_table) = c("object category", "max price", "step size")
priors_table %>%
  kable(caption="Price values for Experiment 2.", align="rrr")
```

## Methods

Each participant saw all 5 objects, which were presented in random order. For each object, participants saw the statement:

* [NAME] bought an [OBJECT]. Please rate how likely it is that the cost of the watch is within each of the following ranges.

Sliders corresponding to each price range were arranged in order from lowest price range to highest. Sliders were initialized in white, with a gray handle at the half-way mark. We required participants to drag the handle in order to register their response -- from "Extremely unlikely" (0) to "Extremely Likely" (1). Once participants dragged the slider, the handle and slider changed color to blue. They submitted all of their responses for a given object at once.

## Results

We normalize slider ratings within each participant and object category, since slider ratings likely reflect relative rather than absolute probabilities (@franke_what_2016).

```{r priors figure, fig.width=10, fig.height=2, fig.cap="Experiment 2 results. Error bars are 95% confidence intervals."}
 breaks_fun <- function(x) {
  if (max(x) < 300) {
    c(0, 100, 200)
  } else if (max(x) < 400) {
    c(0, 100, 200, 300)
  } else {
    c(0, 1000, 2000)
  }
}
df12 %>%
  ggplot(aes(x=mid, y=normed_response)) +
  stat_summary(geom="ribbon", fun.data="mean_cl_boot", alpha=0.5, fill="darkgrey") +
  stat_summary(geom="line", fun.y="mean", alpha=1, colour="darkgrey") +
  facet_wrap(~item, scales="free", ncol=5) +
  xlab("Price value") +
  ylab("Normalized rating") +
  # theme(axis.text.x = element_text(angle = -30, hjust = 0))
  scale_x_continuous(breaks = breaks_fun, limits = c(0, NA))
```

Resuts of Experiment 2 are shown in Figure 3. As stated earlier, we chose our price ranges so that we would get very low endorsements for the higher-price bins and relatively smooth curves to the distributions, which we do in fact see in participant responses.

```{r}
get_priors_cors = function(df) {
  df %>%
  select(item, mid, workerid, response) %>%
  spread(workerid, response) %>%
  select(-c(item, mid)) %>%
  cor() %>%
  .[upper.tri(.,diag = F)] %>%
  mean_cl_boot()
}
priors_cors = get_priors_cors(df12)
# df12 %>% group_by(item) %>%
#   do(get_priors_cors(.)) %>%
#   ungroup()
```

Participants tended to be in agreement. The average correlation between participants' responses was `r priors_cors$y` (CI: [`r priors_cors$ymin`, `r priors_cors$ymax`]), and correlations were similarly high within each object category.

```{r load priors fit}
#50K lag 10 worked before...
m12 = read.csv("../models/results/final_expts_results-S1-sigmax10_20000_burn10000_lag10_chain1_inductive_version_s1_inductive_bins_fit_cost_param_listener0_normed_rating_ignore_last_bin.csv",
  col.names = c("result_type", "variable",
                "IGNORE", "object",
                "value", "probability")) %>%
  filter(result_type == "price_prior")
# m12 %>% ggplot(aes(x=value)) +
#   geom_histogram(bins=30) +
#   facet_wrap(variable ~ object, scales="free")
```

```{r reformat priors fit, fig.width=10, fig.height=3}
quantile_errorbars = function(x) {
  return(data.frame(
    y = mean(x),
    ymin = quantile(x, 0.025),
    ymax = quantile(x, 0.975)
  ))
}
m12_params = m12 %>%
  select(-IGNORE) %>%
  filter(result_type == "price_prior") %>%
  group_by(result_type, variable, object) %>%
  mutate(sample = 1:length(value)) %>%
  ungroup() %>%
  filter(result_type=="price_prior") %>%
  spread(variable, value) %>%
  group_by(object) %>%
  mutate(sigma = mean(sigma)) %>%
  group_by(object, sigma) %>%
  do(quantile_errorbars(.$mu)) %>%
  ungroup() %>%
  gather("region", "mu", c(y, ymin, ymax))
dfm12 = reformatted_df12 %>%
  group_by(object, LB, UB) %>%
  do(mean_cl_boot(.$normed_rating)) %>%
  gather("region", "Prior Elicitation", c(y, ymin, ymax)) %>%
  merge(m12_params) %>%
  mutate(Model = mapply(function(ub, lb, m, s) {
    plnorm(ub, meanlog=m, sdlog=s) - plnorm(lb, meanlog=m, sdlog=s)
  }, UB, LB, mu, sigma)) %>%
  select(-c(sigma, mu)) %>%
  gather("src", "value", c(`Prior Elicitation`, Model)) %>%
  spread(region, value) %>%
  mutate(x = (UB + LB)/2)
```

```{r plot priors fit, fig.width=10, fig.height=2, fig.cap="Log-normal fit for Experiment 2. Error bars are 95% confidence intervals."}
# breaks_fun <- function(x) {
#   if (max(x) < 300) {
#     c(0, 100, 200)
#   } else if (max(x) < 400) {
#     c(0, 100, 200, 300)
#   } else {
#     c(0, 1000, 2000)
#   }
# }
# dfm12 %>%
#   group_by(object, src) %>%
#   mutate(ytotal = sum(y),
#          nx = length(x)) %>%
#   ungroup() %>%
#   # group_by(object, src) %>%
#   # summarise(m = mean(nx), mx = max(nx), mn = min(nx))
#   gather("region", "value", c(y, ymin, ymax)) %>%
#   mutate(value = value / ytotal) %>%
#   spread(region, value) %>%
#   mutate(src = factor(src, levels=c("Prior Elicitation", "Model"))) %>%
#   ggplot(aes(x = x, y = y, ymin = ymin, ymax = ymax, colour = src, fill = src,
#                   linetype = src)) +
#   geom_ribbon(alpha=0.5, colour=NA) +
#   geom_line(alpha=1) +
#   facet_wrap(~object, ncol=5, scales="free") +
#   scale_y_continuous(breaks=c()) +
#   scale_x_continuous(breaks=breaks_fun) +
#   ylab("Density") +
#   xlab("Price Value") +
#   scale_fill_manual(values = c("darkgray", "black")) +
#   scale_colour_manual(values = c("darkgray", "black"))
```

```{r cdf cor priors}
sum_lower = function(df) {
  df$value = mapply(function(p, x) {
    sum(df$value[df$x < x]) %>% return()
  }, df$value, df$x)
  return(df)
}
cdf12 = dfm12 %>%
  gather("region", "value", c(y, ymin, ymax)) %>%
  group_by(object, region, src) %>%
  do(sum_lower(.))
priors_fit_cor = cdf12 %>%
  filter(region=="y") %>%
  spread(src, value) %>%
  with(cor(`Model`, `Prior Elicitation`)^2) %>%
  round(3)
```

Normalized slider ratings are very well-fit by log-normal distributions (see Appendix A for inference details). The empirical CDF is highly correlated with its best-fit log-normal CDF ($R^2 = `r priors_fit_cor`$).

```{r cdf plots priors, fig.width=15, fig.height=3}
# cdf12 %>%
#   spread(region, value) %>%
#   ggplot(aes(x=x, y=y, ymin=ymin, ymax=ymax,
#              fill=src)) +
#   geom_line(aes(colour=src)) +
#   geom_ribbon(alpha=1/5) +
#   facet_wrap(~object, ncol = 5, scales="free") +
#   scale_colour_solarized() +
#   scale_fill_solarized() +
#   geom_hline(yintercept = 1, linetype="dashed", colour="black", alpha=1/5) +
#   ylab("Probability") +
#   xlab("Price")
```

# Model

We base our model of the sorites premise endorsements on @lassiter_adjectival_2015, which uses a scalar adjective model (@lassiter_context_2013) to get a graded endorsement value for sorites. This model of scalar adjectives is a Rational Speech Act model (Frank and Goodman, 2012, Goodman and Stuhlmüller, 2013), which makes use of pragmatic principles {{GRICE}} to resolve vague language in context. In this model, the literal semantics of a scalar adjective is relative to some unspecified threshold.

$$[[\mbox{X is expensive}]]_\theta = \mbox{price}(X) > \theta$$

The literal listener jointly infers the threshold $\theta$ and the value along the scalar adjective dimension, in our case, the price $x$ of the "expensive" item $X$.

$$L_0(x, \theta|\mbox{X is expensive}) \propto P(x)P(\theta)\cdot\delta_{x > \theta}$$

Given a particular price value, the speaker chooses whether to endorse (utterance $u$="yes") or deny (utterance $u$="no") the statement "X is expensive" by soft-maximizing their utility of balancing informativity (the literal listener's ability to infer the correct price, marginalized over their interpretation of $\theta$) and the cost of the utterance.

$$U_S(u; x) = \log\left(\int_\theta L_0(x, \theta|u)d\theta\right) - \mbox{cost}(u)$$

The main task in Experiment 1 was to choose how much to endorse a statement. We model this task as a speaker's choice between two alternative utterances: producing the given utterance to a naive listener, or staying silent (@degen_lost_2014, @franke_typical_2014).

## Concrete premise

The concrete premise in our experiment ("An [OBJECT] that costs \$[PRICE VALUE] is expensive") contains a relative clause. However, we model the endorsement task as choosing between uttering the main clause "The [OBJECT] is expensive," or staying silent, given that the content of the relative clause ("The [OBJECT] costs \$[PRICE VALUE]") is true. Hence, the concrete premise is exactly the scalar adjective utterance of @lassiter_context_2013's model.

{{SHOW COR BETWEEN BOTH PHRASINGS?}}

## Inductive premise

The meaning of the inductive premise is less straightforward. When someone states that "A watch that costs \$3 less than an expensive watch is expensive," what information is assumed to be in common ground, and what information is the speaker trying to communicate? Since the price of the "expensive watch" is unknown to participants, how would they know whether or not to say that a less expensive watch is "still expensive"?

Rather than model the sorites inductive premise as a speaker endorsement task, @lassiter_adjectival_2015 look at the _listener_'s joint posterior distribution over the price of the object $x$ and the threshold $\theta$ given the utterance "an expensive [OBJECT]" and directly compute the marginal probability that $x - \varepsilon > \theta$ is true.

We extend @lassiter_adjectival_2015's approach slightly and compute instead a speaker's probability of communicating that a less expensive item is "still expensive" given a listener's joint posterior over $x$ and $\theta$. That is, we assume participants take the following statements as given:

* An [OBJECT] is expensive.
* Another [OBJECT] costs \$[PRICE VALUE] less.

Similar to @lassiter_adjectival_2015, we use a listener model to simultaneously compute the threshold $\theta$ and the price $x_1$ of the "expensive" object (and consequently the price $x_2$ of the "less expensive" object).

$$\begin{aligned}&L_0(x_1,\theta|X_1\mbox{ is expensive}) \\
&x_2 = x_1 - \varepsilon\end{aligned}$$

However, in our model of the inductive premise, the listener then becomes a speaker. The speaker has the goal to communicate the less expensive price $x_2$ to a naive listener (who knows the threshold but not the price), and must choose whether to make the following statement or stay silent:

* [THE LESS EXPENSIVE OBJECT] is expensive.

We therefore model this naive listener's inferred price distribution with vs. without the statement that the less expensive item would be "still expensive":

$$\begin{aligned}L_0(x_2 | X_2 \mbox{ is expensive}, \theta) &=
\frac{Pr(x_2)\delta_{x_2 > \theta}}{\int_\theta Pr(x)\delta_{x > \theta} d\theta} \\ &=
\left\{\begin{array}{ll}\frac{Pr(x_2)}{1 - {CDF}(\theta)} & \mbox{if } \ x_2 > \theta \\ 0 & \mbox{otherwise}\end{array}\right\}\end{aligned}$$

$$L_0(x_2 | \mbox{silent}, \theta) = Pr(x_2)$$

If the cost of the "still expensive" utternace is $-\frac{1}{\lambda}\log(C_X)$ and the cost of the staying silent is $-\frac{1}{\lambda}\log(C_S)$, the speaker endorsements are:

$$\begin{aligned}S_1(u|x_2, \theta) = \frac{\exp(\lambda \left( \ln(L_0(x_2|u, \theta)) - c(u)\right))}{\sum_{u'} \exp(\lambda\left( \ln(L_0(x_2|u', \theta))-c(u') \right))} = \frac{ C_u \left( L_0(x_2|u, \theta)\right)^\lambda}{\sum_{u'} C_{u'} \left(L_0(x_2|u', \theta)\right)^\lambda}\end{aligned}$$

So for the "still expensive" utterance:

$$\begin{aligned}S_1(X_2 \mbox{ is expensive}|x_2, \theta) &=
\frac{C_X \left(L_0(x_2|X_2 \mbox{ is expensive}, \theta)\right)^\lambda}
{C_X \left(L_0(x_2|X_2\mbox{ is expensive}, \theta)\right)^\lambda + C_S \left(L_0(x_2|\mbox{silent}, \theta)\right)^\lambda} \\
&= 
\left\{\begin{array}{ll}
\frac{C_X \left(\frac{Pr(x_2)}{1 - {CDF}(\theta)}\right)^\lambda}
{C_X \left(\frac{Pr(x_2)}{1 - {CDF}(\theta)}\right)^\lambda + C_S \left(Pr(x_2)\right)^\lambda} & \mbox{if } \ x_2  > \theta \\ 0 & \mbox{otherwise}\end{array}\right\} \\
&= 
\left\{\begin{array}{ll}
\frac{C_X}{C_X + C_S\left(1 - {CDF}(\theta)\right)^\lambda} & \mbox{if } \ x_2 > \theta \\ 0 & \mbox{otherwise}
\end{array}\right\}\end{aligned}$$

Finally, we average over participant's initial guess of $x_1$ and $\theta$ to get the expected endorsement.

$$\begin{aligned}S_1(\mbox{still expensive}) = \int_{x,\theta} L_1(x_1,\theta|\mbox{x is expensive})
\left\{\begin{array}{ll}
  \frac{C_X}{C_X + C_S\left(1 - {CDF}(\theta + \varepsilon)\right)^\lambda} & \mbox{if } \ x_1 - \varepsilon > \theta \\
  0  & \text{otherwise.}
\end{array}\right\}
dxd\theta\end{aligned}$$

If the costs of the two utterances are equal, then the $S_1(\mbox{still expensive}|x, \theta)$ value is always between $1/2$ and $1$ whenever $x_1 -\varepsilon > \theta$. In this case, the expected endorsement is very similar to simply oberving the joint distribution $L_0(x_1, \theta | X_1 \mbox{ is expensive})$ and taking the expectation of $x_1-\varepsilon > \theta$. But the smaller $\theta$ is, the less informative the "still expensive" utterance would be, and so the less likely it is that a speaker would actually endorse it over staying silent.
<!-- As the cost of the "still expensive" utterance goes up relative to staying silent, the speaker is even less likely to endorse the utterance for small values of $\theta$. -->

## Analysis

We jointly model the prior elicitation data from Experiment 2 and the endorsement data from Experiment 1. We use Bayesian methods to infer the most likely values of the latent parameters (object category distribution parameters and speaker optimality). Averaging over the posterior distribution of latent parameters, we show how much variance in the endorsement data we can explain by the pragmatic model.

We model the prior distribution over prices as log-normal, with each object category $o$ having its own mean $\mu_o$ and standard deviation $\sigma_o$. We model slider responses for each bin in Experiment 2 as Gaussian, centered at the probability of that bin with variance $\sigma_{\mbox{bin}}$.^[This is a deviation from @franke2016does's analysis of binned histogram data which used a logit transform in the linking function from probability to slider ratings.] We put uninformative priors over the price distribution parameters $\mu_o \sim \mbox{Uniform}(0, 10), \sigma_o \sim \mbox{Uniform}(0, 10)$, the response parameter $\sigma_{\mbox{bin}} \sim \mbox{Uniform}(0, 0.5)$, and the speaker model parameter $\lambda \sim \mbox{Uniform}(0, 10)$. We assume both utterances (endorsement of the premise or silence) have equal cost.

## Results

```{r fn to fill in samples}
fill_in_samples = function(df) {
  df %>%
    merge(data.frame(value = rep(df$value[[1]], df$freq[[1]])))
}
```

```{r load full model fit bda}
# mfit = read.csv(
#   "../models/results/final_expts_results-S1-sigmax10_10000_burn5000_lag10_chain11_inductive_version_s1_inductive_concrete_inductive_bins_no_cost_param_listener0_normed_rating_ignore_last_bin.csv",
#   col.names = c("result_type", "variable",
#                 "IGNORE", "object",
#                 "value", "probability"))
# mfit = mfit %>%
#   mutate(freq = probability*1000) %>%
#   rowwise() %>%
#   do(fill_in_samples(.)) %>%
#   ungroup()
# write.csv(mfit, file = "mfit_bda.csv", row.names = F)
mfitbda = read.csv("mfit_bda.csv")
# mfit %>%
#   filter(result_type %in% c("global_param", "price_prior")) %>%
#   ggplot(aes(x=value)) +
#   geom_histogram(bins=30) +
#   facet_wrap(variable ~ object, scales="free")
```

```{r calculate map alpha}
# mfit %>%
#   filter(variable == "speakerOptimality") %>%
#   ggplot(aes(x=value)) +
#   geom_histogram()
#   
#   
map_alpha = data.frame(x = seq(0, 1, 0.01)) %>%
  mutate(y = (mfitbda %>%
                filter(variable == "speakerOptimality") %>%
                .$value %>%
                ecdf())(x)) %>%
  filter(abs(y-0.5)<0.01) %>%
  .$x[[1]]
mean_alpha = mfitbda %>%
  filter(variable == "speakerOptimality") %>%
  .$value %>% mean()
```

```{r load full model fit map alpha}
# mfit = read.csv(
#   "../models/results/final_expts_results-S1-sigmax10_10000_burn5000_lag10_chain1_inductive_version_s1_inductive_bins_no_cost_param_map_alpha_listener0_normed_rating_ignore_last_bin.csv",
#   col.names = c("result_type", "variable",
#                 "IGNORE", "object",
#                 "value", "probability"))
# mfit = mfit %>%
#   mutate(freq = probability*1000) %>%
#   rowwise() %>%
#   do(fill_in_samples(.)) %>%
#   ungroup()
# write.csv(mfit, file = "mfit.csv", row.names = F)
mfit = read.csv("mfit.csv")
# mfit %>%
#   filter(result_type %in% c("global_param", "price_prior")) %>%
#   ggplot(aes(x=value)) +
#   geom_histogram(bins=30) +
#   facet_wrap(variable ~ object, scales="free")
```

```{r reformat full model fit (priors), fig.width=10, fig.height=3}
mfit_params = mfit %>%
  select(-IGNORE) %>%
  filter(result_type == "price_prior") %>%
  group_by(result_type, variable, object) %>%
  mutate(sample = 1:length(value)) %>%
  ungroup() %>%
  filter(result_type=="price_prior") %>%
  spread(variable, value) %>%
  group_by(object) %>%
  mutate(sigma = mean(sigma)) %>%
  group_by(object, sigma) %>%
  do(quantile_errorbars(.$mu)) %>%
  ungroup() %>%
  gather("region", "mu", c(y, ymin, ymax))
dfmfit12 = reformatted_df12 %>%
  group_by(object, LB, UB) %>%
  do(mean_cl_boot(.$normed_rating)) %>%
  gather("region", "Prior Elicitation", c(y, ymin, ymax)) %>%
  merge(mfit_params) %>%
  mutate(Model = mapply(function(ub, lb, m, s) {
    plnorm(ub, meanlog=m, sdlog=s) - plnorm(lb, meanlog=m, sdlog=s)
  }, UB, LB, mu, sigma)) %>%
  select(-c(sigma, mu)) %>%
  gather("src", "value", c(`Prior Elicitation`, Model)) %>%
  spread(region, value) %>%
  mutate(x = (UB + LB)/2)
```

```{r plot full model fit (priors), fig.width=10, fig.height=2, fig.cap="Posterior price distributions fit to Experiments 1 and 2. Error bars are 95% confidence intervals."}
breaks_fun <- function(x) {
  if (max(x) < 300) {
    c(0, 100, 200)
  } else if (max(x) < 400) {
    c(0, 100, 200, 300)
  } else {
    c(0, 1000, 2000)
  }
}
dfmfit12 %>%
  group_by(object, src) %>%
  mutate(ytotal = sum(y),
         nx = length(x)) %>%
  ungroup() %>%
  # group_by(object, src) %>%
  # summarise(m = mean(nx), mx = max(nx), mn = min(nx))
  gather("region", "value", c(y, ymin, ymax)) %>%
  mutate(value = value / ytotal) %>%
  spread(region, value) %>%
  mutate(src = factor(src, levels=c("Prior Elicitation", "Model"))) %>%
  ggplot(aes(x = x, y = y, ymin = ymin, ymax = ymax, colour = src, fill = src,
                  linetype = src)) +
  geom_ribbon(alpha=0.5, colour=NA) +
  geom_line(alpha=1) +
  facet_wrap(~object, ncol=5, scales="free") +
  scale_y_continuous(breaks=c()) +
  scale_x_continuous(breaks=breaks_fun) +
  ylab("") +
  xlab("Price Value") +
  scale_fill_manual(values = c("darkgray", "black")) +
  scale_colour_manual(values = c("darkgray", "black"))
```

```{r cdf cor full model fit}
sum_lower = function(df) {
  df$value = mapply(function(p, x) {
    sum(df$value[df$x < x]) %>% return()
  }, df$value, df$x)
  return(df)
}
cdf12_full = dfmfit12 %>%
  gather("region", "value", c(y, ymin, ymax)) %>%
  group_by(object, region, src) %>%
  do(sum_lower(.))
priors_fit_cor_full_model = cdf12_full %>%
  filter(region=="y") %>%
  spread(src, value) %>%
  with(cor(`Model`, `Prior Elicitation`)^2) %>%
  round(3)
```



```{r priors split half}
all_workers = df12$workerid %>% unique()
split_half_cor_priors = function(df) {
  return(function(x) {
    half = sample(
      all_workers,
      size = length(all_workers)/2,
      replace = F
    )
    df %>% mutate(half = ifelse(workerid %in% half, "A", "B")) %>%
      mutate(x = lower) %>%
      group_by(half, x, item) %>%
      summarise(value = mean(normed_response)) %>%
      ungroup() %>%
      group_by(half, item) %>%
      do(sum_lower(.)) %>%
      ungroup() %>%
      spread(half, value) %>%
      with(., cor(A, B)^2)
  })
}
n_resamples = 1000
resamples = sapply(1:n_resamples, split_half_cor_priors(df12))
split_half_conf_priors = quantile(resamples, probs = c(0.025, 0.975)) %>% round(3) %>% unname()
split_half_correlation_priors = mean(resamples) %>% round(3)
```

The posterior price distributions inferred by fitting to both Experiments 1 and 2 (shown in Figure 4) are very close to the normalized ratings from Experiment 1 (comparing empirical vs. model CDF, $R^2 = `r priors_fit_cor_full_model`$).

```{r reformat full model fit (sorites)}
dfmfit = mfit %>% filter(result_type %in% c("S1", "Inductive")) %>%
  group_by(result_type, object, variable) %>%
  do(quantile_errorbars(.$value)) %>%
  ungroup() %>%
  gather("region", "value", c(y, ymin, ymax)) %>%
  mutate(qtype = ifelse(result_type=="Inductive", "inductive", "concrete")) %>%
  rename(dollar_amount = variable) %>%
  mutate(dollar_amount = num(dollar_amount)) %>%
  mutate(src = "Model") %>%
  select(qtype, object, dollar_amount, region, value, src) %>%
  rbind(
    df11 %>% group_by(qtype, object, dollar_amount) %>%
      do(mean_cl_boot(.$response)) %>%
      ungroup() %>%
      mutate(src = "Sorites Experiment") %>%
      gather("region", "value", c(y, ymin, ymax)) %>%
      mutate(dollar_amount = num(dollar_amount)) %>%
      select(qtype, object, dollar_amount, region, value, src)) %>%
  spread(region, value)
```

```{r sorites fit figure, fig.width=10, fig.height=4, fig.cap="Results of Experiment 1. Error bars are 95% confidence intervals."}
 breaks_fun <- function(y) {
  if (max(y) < 2) {
    seq(0, 1, 0.2)
  } else {
    1:9
  }
 }
limits_fun <- function(y) {
  if (max(y) < 2) {
    c(0.9, 9.1)
  } else {
    c(0, 1.05)
  }
}
dfmfit %>%
  # gather("region", "value", c(y, ymin, ymax)) %>%
  # mutate(value = ifelse(src=="Model", num(value)*8+1, num(value))) %>%
  # spread(region, value) %>%
  mutate(src = factor(src, levels=c("Sorites Experiment", "Model"))) %>%
  ggplot(aes(x=dollar_amount, y=y, ymax=ymax, ymin=ymin, colour=qtype, fill=qtype, linetype=qtype, shape=qtype)) +
  geom_errorbar() +
  geom_point() +
  facet_grid(src~object, scales="free") +
  # scale_y_continuous(breaks=1:9, limits=c(0.9, 9.1)) +
  # scale_x_continuous(breaks=breaks_fun) +
  scale_y_continuous(breaks=breaks_fun) +#, limits=limits_fun) +
  xlab("Dollar Amount") +
  ylab("Endorsement Rating") +
  scale_fill_manual(values = c("darkgray", "black")) +
  scale_colour_manual(values = c("darkgray", "black"))
```

```{r sorites fit cors}
concrete_cor = dfmfit %>% select(-c(ymax, ymin)) %>%
  spread(src, y) %>%
  filter(qtype=="concrete") %>%
  with(cor(Model, `Sorites Experiment`)^2 %>% round(3))
inductive_cor = dfmfit %>% select(-c(ymax, ymin)) %>%
  spread(src, y) %>%
  filter(qtype=="inductive") %>%
  with(cor(Model, `Sorites Experiment`)^2 %>% round(3))
```

```{r sorites cors figure, fig.width=8, fig.height=3}
dfmfit %>%
  gather("region", "value", c(y, ymin, ymax)) %>%
  mutate(variable = paste(src, region, sep=".")) %>%
  select(-c(src, region)) %>%
  spread(variable, value) %>%
  ggplot(aes(x=Model.y, xmin=Model.ymin, xmax=Model.ymax,
             y=`Sorites Experiment.y`,
             ymin=`Sorites Experiment.ymin`,
             ymax=`Sorites Experiment.ymax`,
             colour=object, shape=object)) +
  geom_errorbarh() +
  geom_pointrange() +
  scale_colour_grey() +
  facet_wrap(~qtype, scales="free") +
  # scale_y_continuous(breaks=1:9) +
  # xlim(0,1) +
  ylab("Sorites Endorsements") +
  xlab("Model Fit")
```

```{r sorites split half}
all_workers = df11$workerid %>% unique()
split_half_cor = function(df) {
  return(function(x) {
    half = sample(
      all_workers,
      size = length(all_workers)/2,
      replace = F
    )
    df %>% mutate(half = ifelse(workerid %in% half, "A", "B")) %>%
      group_by(half, qtype, object, dollar_amount) %>%
      summarise(response = mean(response)) %>%
      spread(half, response) %>%
      with(., cor(A, B)) %>%
      .^2
  })
}
n_resamples = 1000
resamples = sapply(1:n_resamples, split_half_cor(df11))
split_half_conf = quantile(resamples, probs = c(0.025, 0.975)) %>% round(3) %>% unname()
split_half_correlation = mean(resamples) %>% round(3)

resamples = sapply(1:n_resamples, split_half_cor(df11 %>% filter(qtype=="concrete")))
split_half_conf_concrete = quantile(resamples, probs = c(0.025, 0.975)) %>% round(3) %>% unname()
split_half_correlation_concrete = mean(resamples) %>% round(3)

resamples = sapply(1:n_resamples, split_half_cor(df11 %>% filter(qtype=="inductive")))
split_half_conf_inductive = quantile(resamples, probs = c(0.025, 0.975)) %>% round(3) %>% unname()
split_half_correlation_inductive = mean(resamples) %>% round(3)

# concrete_cor
# split_half_conf_concrete
# inductive_cor
# split_half_conf_inductive
```

The posterior endorsement levels (expected probability of choosing the utterance) for Experiment 2 as well as participants actual responses are shown in Figures 5 and 6. The correlation between participants' mean responses and the model's mean endorsement is very high ($R^2=`r inductive_cor`$ for the inductive premise and $R^2=`r concrete_cor`$ for the concrete premise). These values are close to the split-half correlation (for inductive, mean: `r split_half_correlation_inductive`, CI: [`r split_half_conf_inductive[1]`, `r split_half_conf_inductive[2]`]; for concrete, mean: `r split_half_correlation_concrete`, CI: [`r split_half_conf_concrete[1]`, `r split_half_conf_concrete[2]`]), which represents a ceiling on explainability. For the "watches" object category, we find that participants' endorsements of the concrete premise "A watch that costs \$[PRICE VALUE] is expensive," are noticeably higher than the model's.  {{WHY THO?}}

## Discussion

{{SUMMARIZE TAKE-AWAYS}}

# General Discussion

{{SKETCH DISCUSSION}}

# References

\appendix

# Inference details

{{WRITE THIS}}
