// time webppl generics-bda-S1-iMH.wppl --require utils 1

// Load index as last command line input.
var chain = last(process.argv);

// Justine's give-a-number data.
var d_giveanumber = dataFrame(
  utils.readCSV("../data/priors/reformatted_give_a_number.csv").data
);

// Focus on this experiment for fitting first.
// This experiment used a pretty good range of values.
var expt_id = "07c";

// Sorites experiment data.
var d_sorites = _.filter(dataFrame(
  utils.readCSV("../data/sorites/sorites.csv").data
));
// Unique objects from sorites experiments.
var objects = levels(d_sorites, "object");
var experiment_ids = levels(d_sorites, "id");

// Create bins for each item that coordinate well with the experiment design.
// display(_.fromPairs(map(function(item){
//   return (item, setup_bins(d_sorites, expt_id, item))
// }, objects)));
var bins = _.fromPairs(map(function(item){
  return [item, setup_bins(d_sorites, experiment_ids, item)]
}, objects));
// var bins = {
//   "laptop": setup_bins(d_sorites, expt_id, "laptop"),
//   "watch": setup_bins(d_sorites, expt_id, "watch"),
//   "coffee maker": setup_bins(d_sorites, expt_id, "coffee maker"),
//   "headphones": setup_bins(d_sorites, expt_id, "headphones"),
//   "sweater": setup_bins(d_sorites, expt_id, "sweater")
// };

var thetaPriors = _.fromPairs(map(function(item) {
  return [item, _.fromPairs(map(function(id) {
    return [id, Categorical({
      vs: bins[item][id]["theta"],
      ps: bins[item][id]["theta_prob"]
    })];
  }, experiment_ids))];
}, objects));

// var thetaPriors = {
//   "laptop": Categorical({vs: bins["laptop"]["theta"],
//                          ps: bins["laptop"]["theta_prob"]}),
//   "watch": Categorical({vs: bins["watch"]["theta"],
//                          ps: bins["watch"]["theta_prob"]}),
//   "coffee maker": Categorical({vs: bins["coffee maker"]["theta"],
//                          ps: bins["coffee maker"]["theta_prob"]}),
//   "headphones": Categorical({vs: bins["headphones"]["theta"],
//                          ps: bins["headphones"]["theta_prob"]}),
//   "sweater": Categorical({vs: bins["sweater"]["theta"],
//                          ps: bins["sweater"]["theta_prob"]}),
// }

var bins_filename = "results/bins.json";
utils.writeJSON(bins, bins_filename);
display("bins file written to: " + bins_filename);


var utterancePrior = Infer({model: function(){
	return uniformDraw(["expensive", "silence"])
}});

var meaning = function(utt,state, theta) {
  return utt=="expensive"? state > theta :
         utt=="expensive is false"? state<=theta :
         utt=='silence'? true :
         true
};

var model = function(){

  // Prior parameters
  var MUMAX = 10; // maximum mu for lognormal price distributions
  var SIGMAX = 3; // maximum sigma for lognormal price distributions

  // Iterate over all items in the sorites experiments.
  foreach(objects, function(item) {

    // Parameters for lognormal price distributions, different parameters for
    // each object.
    var item_params = {
      mu: uniformDrift({a: 0, b: MUMAX, width: 1}),
      sigma: uniformDrift({a: 0, b: SIGMAX, width: 0.5})
    };

    var item_giveanumber = _.filter(d_giveanumber, {"object": item});

    // Fit lognormal parameters to give-a-number data.
    // Factor by likelihood of sampled responses from give-a-number task.
    mapData(
      {data: item_giveanumber},
      function(d) {
        // Assume log of price is normally distributed, so use lognormal density
        // function.
        factor(utils.lognormalScore(d.price, item_params));
      }
    );

    query.add(["price_prior", "mu", "NA", item], item_params.mu);
    query.add(["price_prior", "sigma", "NA", item], item_params.sigma);
  })

	return query;
}


// For *just* fitting lognormal params to give a number data:
//   - Takes 8s
//   - Fits give a number data well
// Adding setup of discrete priors and listener0, it takes 10s.
// (Actually computing listener0 takes 13s.)
// Setting up every function up to S1 takes 12s.
// Adding dollar_amounts and an empty foreach takes 12s.
// Actually running S1 to get endorsements takes 28s.
// And observing the endorsement with mapData takes 1m.
// And recording endorsements takes about 1m.
// Adding likert takes 1m 30s.
// Doubling nbins takes ~2m and fits much better, and doubling nbins again:
//   - takes 2m 30s
//   - fits concrete premise well, but not perfectly.
//   - Doesn't fit priors as well when we fit the concrete premise.
//   - adding iterations does not help.
//   - btw, 8x takes __ and fits __.
// Alternatively, iterating through all experiments
//   - takes 8m 30s
//   - fits terribly
// Alternatively, computing a joint dist:
//   - by itself takes takes 1m 30s.
// var totalIterations = 5000, lag =  10;

// var totalIterations = 10000, lag = 20;

// // For *just* fitting lognormal params to give a number data, takes 40s.
// // For the whole shebang with one experiment, takes ~2m, 30s.
var totalIterations = 50000, lag =  10;

// // 71m
// var totalIterations = 500000, lag =  10;
// // var totalIterations = 500000, lag =  200;

var samples = totalIterations/lag, burn = totalIterations / 2;

var outfile = 'results-prior-'+totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'

var posterior = Infer({
  model: model,
	method: "incrementalMH",
  samples: samples,
  burn: burn,
  lag: lag,
  verbose: T,
  verboseLag: totalIterations / 20
})

utils.writeQueryERP(posterior, "results/" + outfile, ["type", "param", "property", "category", "val"]);

"written to " + outfile;