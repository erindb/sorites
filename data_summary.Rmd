---
title: "Sorites Data Summary"
author: "Erin Bennett"
output: "pdf_document"
header-includes:
   - \usepackage{tikz}
   - \usetikzlibrary{bayesnet}
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F, sanitiz=F, fig.width = 5, fig.height = 3)
```

```{r load libraries}
source("~/Settings/startup.R")
library(knitr)
library(pander)
```

# Wording used in sorites experiments

```{r load design descriptions}
sorites_designs = read.csv("data/sorites/sorites_designs.csv",
                           stringsAsFactors = F)
sorites_designs %>%
  select(-prompt, -left, -right, -concrete, -inductive) %>%
  rename(`inductive phrasing` = inductive_label) %>%
  pander(.,
       caption="Sorites variations",
       align=rep("l", ncol(sorites_designs)))
lookup_phrasing = function(inductive_phrasing) {
  return((
    sorites_designs %>%
      filter(inductive_label==inductive_phrasing)
  )$inductive[[1]])
}
```

Possible phrasings of inductive premise:

* relative: "`r lookup_phrasing("relative")`"
* conditional: "`r lookup_phrasing("conditional")`"

Consistent across all experiments:

* Concrete premise: "`r sorites_designs$concrete[[1]]`"
* Prompt: "`r sorites_designs$prompt[[1]]`"
* Left (lower) label of likert scale: "`r sorites_designs$left[[1]]`""
* Right (higher) label of likert scale: "`r sorites_designs$right[[1]]`""

*In experiments 7a and 7b, phrasing was randomized between participants (either relative or conditional), but I did not record which phrasing was used for which participant

# Results of sorites experiments

```{r load (and reformat) data}
## this is the script for reformatting sorites data into one single datafile
RUN_REFORMAT = F
if (RUN_REFORMAT) {
  lookup_date = function(experiment_id) {
    return((
      sorites_designs %>%
        filter(char(id)==experiment_id)
    )$date[[1]])
  }
  find_sorites_filename = function(experiment_id) {
    directory = "data/sorites/"
    filenames = list.files(directory)
    filename = filenames[
      grep(paste("data_exp", experiment_id, sep=""),
           filenames)
      ]
    return(paste(directory, filename, sep=""))
  }
  read_sorites_data = function(experiment_id) {
    raw_df_all_columns = read.csv(
      find_sorites_filename(experiment_id),
      stringsAsFactors = F
    )
    
    ## for experiment 10 data format:
    if ("Answer.responses" %in% names(raw_df_all_columns)) {
      raw_df_all_columns$Answer.questions = raw_df_all_columns$Answer.responses
    }
    if (!("Answer.phrasing" %in% names(raw_df_all_columns))) {
      raw_df_all_columns$Answer.phrasing = NA
    }
    if ("Answer.time_in_minutes" %in% names(raw_df_all_columns)) {
      raw_df_all_columns$time_in_minutes = raw_df_all_columns$Answer.time_in_minutes
    } else {
      raw_df_all_columns$time_in_minutes = NA
    }
    if ("Answer.subj_data" %in% names(raw_df_all_columns)) {
      subj_data = do.call(rbind, lapply(raw_df_all_columns$Answer.subj_data, fromJSON)) %>%
        as.data.frame
      raw_df_all_columns$Answer.comments = unlist(subj_data$comments)
      raw_df_all_columns$Answer.language = unlist(subj_data$language)
      raw_df_all_columns$Answer.education = unlist(subj_data$education)
      raw_df_all_columns$Answer.age = unlist(subj_data$age)
    } else {
      raw_df_all_columns$Answer.education = NA
    }
    
    ## select only the useful columns
    raw_df = raw_df_all_columns %>%
      rename(comments = Answer.comments,
             language = Answer.language,
             questions = Answer.questions,
             education = Answer.education,
             phrasing = Answer.phrasing,
             age = Answer.age) %>%
      select(workerid, reward, comments,
             age, language, questions) %>%
      mutate(workerid = paste(workerid, experiment_id, sep="_"))
    
    reformatted_df = do.call(rbind, mapply(function(qn, workerid_for_merge) {
      return(fromJSON(qn) %>% mutate(workerid=workerid_for_merge))
    }, raw_df$questions, raw_df$workerid, SIMPLIFY = F) %>% unname) 
    ## some versions collect reaction time, etc.:
    if (!("rt" %in% names(reformatted_df))) { reformatted_df$rt = NA }
    if (!("level" %in% names(reformatted_df))) { reformatted_df$level = NA }
    if (!("sigs" %in% names(reformatted_df))) { reformatted_df$sigs = NA }
    if (!("qNumber" %in% names(reformatted_df))) { reformatted_df$qNumber = NA }
    if ("qType" %in% names(reformatted_df)) { reformatted_df = reformatted_df%>%rename(qtype=qType) }
    if ("dollarAmt" %in% names(reformatted_df)) {
      reformatted_df = reformatted_df%>%rename(dollar_amount=dollarAmt)
    }
    if ("item" %in% names(reformatted_df)) {
      reformatted_df = reformatted_df%>%rename(object=item)
    }
    df = merge(
      raw_df %>% select(-questions),
      reformatted_df,
      by=c("workerid")
    ) %>%
      mutate(id = experiment_id,
             date = lookup_date(experiment_id))
    if (!("phrasing" %in% names(df))) { df$phrasing = NA }
    return(df)
  }
  df = do.call(rbind, lapply(c("00", "01", "07a", "07b", "07c", "10", "11"), read_sorites_data)) %>%
    as.data.frame %>% flatten %>% ungroup %>% mutate(
    dollar_amount = as.numeric(unname(sapply(char(dollar_amount), function(money_string) {
      if (substr(money_string, 1, 1)=="$") {
        return(substr(money_string, start=2, stop=nchar(money_string)))
      } else {
        return(money_string)
      }
    }))),
    qtype = ifelse(qtype=="eps", "inductive", qtype),
    qtype = ifelse(qtype=="val", "concrete", qtype),
    qtype = factor(qtype),
    phrasing = ifelse(id %in% c("00", "01"), "relative", phrasing),
    response = num(response)
  )
  
  write.csv(df, "data/sorites/combined_reformatted_sorites_data.csv", row.names = F)
} else {
  df = read.csv("data/sorites/combined_reformatted_sorites_data.csv")
}
df = df %>% mutate(
  phrasing = ifelse(phrasing=='"relative"', "relative", phrasing),
  phrasing = ifelse(phrasing=="relative_clause", "relative", phrasing),
  phrasing = ifelse(phrasing=='"conditional"', "conditional", phrasing),
  phrasing = factor(phrasing),
  id = factor(id)
)
```

```{r}
RUN_AGG = F
## computing confidence intervals takes a long time.
## so just cache the results of this most of the time
if (RUN_AGG) {
  agg = df %>%
  group_by(id, qtype, phrasing, object, dollar_amount) %>%
  summarise(low = ci.low(response),
            high = ci.high(response),
            response = mean(response))
write.csv(agg, ".agg_cache.csv", row.names = F)
}  else {
agg = read.csv(".agg_cache.csv")
}
agg = agg %>% mutate(phrasing = factor(phrasing))
```

```{r, fig.height=4, fig.width=12}
opacity = 0.5
agg %>% ggplot(., aes(x=dollar_amount, y=response, colour=phrasing)) +
  geom_point(alpha=opacity) +
  # geom_line(alpha=opacity) +
  geom_errorbar(aes(ymin=low, ymax=high), width=0, alpha=opacity) +
  facet_grid(qtype~object, scale="free_x") +
  ylim(1, 9) +
  # scale_colour_brewer(type="qual", palette = 3) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggsave("sorites_data.png", width=12, height=4)
```

# Priors experiments

give a number: i don't know Justine's design for this.

```{r, fig.width=8, fig.height=4}
give_a_number = read.csv("data/priors/give-a-number.csv") %>% select(-X) %>%
  mutate(item = ifelse(item=="coffee.maker", "coffee maker", char(item)))
current_item = "coffee maker"
iterations = 2000
n_data = nrow(give_a_number)
max_values = give_a_number %>% group_by(item) %>%
  summarise(max = max(price))
rs = do.call(
  rbind,
  lapply(
    unique(give_a_number$item),
    function(current_item) {
      give_a_number_params = webppl(
        program_file = "models/prior_fits/give_a_number.wppl",
        inference_opts = list(method="MCMC",
                              samples=iterations,
                              burn=100,
                              skip=10),
        model_var = "model",
        data_var = "ARGS",
        data = list(
          samples=(give_a_number %>% filter(item==current_item))$price,
          N=n_data)) %>%
        mutate(item = current_item)
      return(give_a_number_params)
    }))
inferred_parameters = rs %>% group_by(item, Parameter) %>%
  summarise(value = mean(value)) %>%
  spread(Parameter, value) %>% as.data.frame
row.names(inferred_parameters) = inferred_parameters$item
posterior_predictive = give_a_number %>%
  mutate(price = mapply(function(current_item) {
    return(exp(rnorm(1,
                 inferred_parameters[current_item, "mu"], 
                 inferred_parameters[current_item, "sig"])))
  }, item))
inferred_parameters
rbind(give_a_number %>%
        mutate(source="give a number"),
      posterior_predictive %>%
        mutate(source="posterior predictive")) %>%
  ggplot(., aes(x=price, colour=source)) +
  geom_density(alpha=1/2) +
  scale_colour_brewer(type="qual", palette = 3) +
  facet_wrap(~item, scale="free")
```

experiment 02

```{r}
# exp2 = read.csv("data/priors/data_exp02_2013_10_08_08.csv")
```

Instructions:

In this experiment, we would like you to imagine that our store has compiled an inventory list for insurance purposes. Unfortunately, the store only had one copy of the paper where we wrote all this information, and that paper has been badly treated. The prices have faded away and been lost. We would like your best guess as to what those prices should be.

We can get a little bit of information about the price by looking at the the color and font of each entry. Items that cost more than $2000 have to be declared seperately and require additional paperwork, so these are written in blue italics. Please only guess a price above $2000 if the entry is written in blue italics, and please only guess a price below (or equal to) $2000 if the entry is written in plain black text.

Although we know that you cannot recover the original prices exactly, keep in mind that it is in the store's best interest if your guesses are as close to the original prices as possible.

Prompt: Items over $CUTOFF are in blue italics.

experiment 03

In each scenario, someone has just bought an item. Please give your best estimate of the price of the item. You will do this by rating how likely you think it is that the actual price is within each of NBINS different ranges.

NAME bought a new *ITEM*.

Please rate how likely it is that the cost of the *ITEM* is within each of the following ranges.

experiment 04

same as 2

experiment 05

same as 2

experiment 06

condition A: same as 2

condition B: NAME bought new *ITEM* It was *expensive*.

experiment 08

same as 2, but ITEM is colored differently for different items

experiment 09

	
NAME (saw|bought|met) an *ITEM*.
OR
NAME (saw|bought|met) an *ITEM*. NAME says, "The ITEM was *ADJECTIVE*."

Please rate how likely it is that the (height|cost|age) of the ITEM is within each of the following ranges.

25-30 ft
$250-$300
25-30 yrs

# Model

## Definitions

* $w_i$ := width of histogram bins for item $i$
* $x_i$ := sample in give a number trial
* $p_{ib}$ := true probability of bin $b$ for item $i$
* $d_{ib}$ := slider rating for bin $b$ for item $i$
* $S2(I_{i\varepsilon})$ := RSA S2(L1(expensive) + $\varepsilon$) for item $i$
* $S2(C_{iv})$ := RSA S2(expensive) for item $i$
* $s^I_{i\varepsilon}$ := binarization of likert rating for inductive premise for item $i$ and epsilon $\varepsilon$
* $s^C_{iv}$ := binarization of likert rating for concrete premise for item $i$ and value $v$
* $\alpha^I_2$ := speaker rationality for S1 for inductive premise

## Diagram

\tikz{
  \node[latent,] (mu) {$\mu_i$};
  \node[latent, right=of mu] (sig) {$\sigma_i$};
  
  \node[above=of mu] (mumax) {$\mu^{max}$};
  \node[above=of sig] (sigmax) {$\sigma^{max}$};
  \node[right=4cm of sigmax] (sigbin) {$\sigma_{binned\ hist}$};
  \node[right=of sigbin] (alpha1max) {$\alpha_1^{max}$};
  \node[right=of alpha1max] (alpha2max) {$\alpha_2^{max}$};
  
  \node[det, below=of mu, below=of sig] (pbin) {$p_{ib}$};
  \node[obs, below=of pbin] (dbin) {$d_{ib}$};
  
  \node[obs, left=of pbin] (giveanum) {$x_{i}$};
  
  \node[latent, below=of alpha1max] (alpha2C) {$\alpha_{2}^{C}$};
  \node[latent, below=of alpha2max] (alpha1I) {$\alpha_{1}^{I}$};
  \node[latent, left=of alpha2C] (alpha1C) {$\alpha_{1}^{C}$};
  \node[latent, right=of alpha1I] (alpha2I) {$\alpha_{2}^{I}$};
  
  \node[latent, below=of pbin, xshift=2cm] (s2concrete) {$S2(C_{iv})$};
  \node[latent, right=of s2concrete] (s2inductive) {$S2(I_{i\varepsilon})$};
  
  \node[obs, below=of s2inductive] (sI) {$s^{I}_{i\varepsilon}$};
  \node[obs, below=of s2concrete] (sC) {$s^{C}_{iv}$};
  
  \edge {mumax} {mu}
  \edge {sigmax} {sig}
  \edge {mu, sig} {pbin}
  \edge {mu, sig} {giveanum}
  \edge {pbin, sigbin} {dbin}
  \edge {pbin} {s2inductive, s2concrete}
  \edge {s2inductive} {sI}
  \edge {s2concrete} {sC}
  \edge {alpha1I, alpha2I} {s2inductive}
  \edge {alpha1C, alpha2C} {s2concrete}
  \edge {alpha1max} {alpha1C, alpha1I}
  \edge {alpha2max} {alpha2C, alpha2I}
  
  \plate {bin} {
    (pbin) (dbin)
  } {$b\in{Bins_i}$};
  \plate {epsilon} {
    (s2inductive) (sI)
  } {$\varepsilon \in Epsilons$};
  \plate {value} {
    (s2concrete) (sC)
  } {$v \in Values$};
  \plate {item} {
    (mu) (sig)
    (giveanum)
    (bin.south east)
    (epsilon.south east)
    (value.south east)
    (s2inductive) (s2concrete)
  } {$i\in{Objects}$};
}

# Distributions/Functions/Values:

Experiment design parameters:

* $Objects$
* $Bins$
* $Epsilons$
* $Values$

Assumed model parameters:

* $\mu^{max}$ = ??
* $\sigma^{max}$ = ??
* $\sigma_{binned\ hist}$ = ??
* $\alpha_1^{max}$ = 20
* $\alpha_2^{max}$ = 5

Inferred Latent variables:

* $\mu_i \sim \mathcal{U}\{0, \mu^{max}\}$
* $\sigma_i \sim \mathcal{U}\{0, \sigma^{max}\}$
* $\alpha_1^I \sim \mathcal{U}\{0, \alpha_1^{max}\}$
* $\alpha_2^I \sim \mathcal{U}\{0, \alpha_2^{max}\}$
* $\alpha_1^C \sim \mathcal{U}\{0, \alpha_1^{max}\}$
* $\alpha_2^C \sim \mathcal{U}\{0, \alpha_2^{max}\}$
* $p_{ib} = \int_{LB_{ib}}^{UB_{ib}} \varphi(ln(t)|\mu_i, \sigma_i) dt$

Observations from experimental data:

* $d_{ib} \sim \mathcal{N}(p_{ib}, \sigma_{binned\ hist})$
